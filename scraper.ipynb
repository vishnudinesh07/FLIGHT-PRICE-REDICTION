{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07dfaacc",
   "metadata": {},
   "source": [
    "#  Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41746800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2fb3624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to chromedriver\n",
    "chromedriver_path =  \"/Users/vishnudinesh/Desktop/web-scraping/chromedriver.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eee435b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# launching the driver\n",
    "driver = webdriver.Chrome(chromedriver_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c518ac",
   "metadata": {},
   "source": [
    "### User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "086a9e1b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter -1 when done.\n",
      "----------\n",
      "From which city?\n",
      "RUH\n",
      "Where to?\n",
      "NYC\n",
      "----------\n",
      "From which city?\n",
      "SVO\n",
      "Where to?\n",
      "PAR\n",
      "----------\n",
      "From which city?\n",
      "-1\n",
      "\n",
      "Routes:\n",
      "RUH => NYC\n",
      "SVO => PAR\n"
     ]
    }
   ],
   "source": [
    "# get user input for routes\n",
    "sources = []\n",
    "destinations = []\n",
    "print(\"Please enter -1 when done.\")\n",
    "print(\"-\"*10)\n",
    "while True:\n",
    "    sources.append(input(\"From which city?\\n\"))\n",
    "    if \"-1\" in sources: \n",
    "        sources.pop(-1)\n",
    "        break\n",
    "    destinations.append(input(\"Where to?\\n\"))\n",
    "    if \"-1\" in destinations: \n",
    "        sources.pop(-1)\n",
    "        destinations.pop(-1)\n",
    "        break\n",
    "    print(\"-\"*10)\n",
    "\n",
    "print(\"\\nRoutes:\")\n",
    "for i in range(len(sources)):\n",
    "    print(f\"{sources[i]} => {destinations[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "854eb791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Date, Please use YYYY-MM-DD format only 2022-02-01\n",
      "End Date, Please use YYYY-MM-DD format only 2022-02-02\n"
     ]
    }
   ],
   "source": [
    "# get user input for period (start and end date)\n",
    "start_date = np.datetime64(input('Start Date, Please use YYYY-MM-DD format only '))\n",
    "end_date = np.datetime64(input('End Date, Please use YYYY-MM-DD format only '))\n",
    "days = end_date - start_date\n",
    "num_days = days.item().days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3496081",
   "metadata": {},
   "source": [
    "### Define functions for scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10169a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_airlines(soup):\n",
    "    airline = []\n",
    "    airlines = soup.find_all('span',class_='codeshares-airline-names',text=True)\n",
    "    for i in airlines:\n",
    "        airline.append(i.text)\n",
    "    return airline\n",
    "    \n",
    "def get_total_stops(soup):\n",
    "    stops_list = []\n",
    "    stops = soup.find_all('div',class_='section stops')\n",
    "\n",
    "    for i in stops:\n",
    "        for j in i.find_all('span',class_='stops-text'):\n",
    "               stops_list.append(j.text)\n",
    "    return stops_list\n",
    "\n",
    "def get_price(soup):\n",
    "    prices = []\n",
    "    price = soup.find_all('div',class_='Flights-Results-FlightPriceSection right-alignment sleek')\n",
    "\n",
    "    for i in price:\n",
    "        for j in i.find_all('span', class_='price-text'):\n",
    "            prices.append(j.text)\n",
    "    return prices\n",
    "\n",
    "def get_duration(soup):\n",
    "    duration_list = []\n",
    "    duration = soup.find_all('div' , class_='section duration allow-multi-modal-icons')\n",
    "    for i in duration:\n",
    "        for j in i.find_all('div',class_='top'):\n",
    "            duration_list.append(j.text)\n",
    "    return duration_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79ac2d4",
   "metadata": {},
   "source": [
    "## Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a522f718",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [01:37<00:00, 48.64s/it]\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully saved RUH => NYC route as RUH_NYC.csv \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [01:07<00:00, 33.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully saved SVO => PAR route as SVO_PAR.csv \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(sources)):\n",
    "    column_names = [\"Airline\", \"Source\", \"Destination\",\"Duration\" ,\"Total stops\", \"Price\",\"Date\"]\n",
    "    df = pd.DataFrame(columns = column_names)\n",
    "    for j in tqdm(range(num_days+1)):\n",
    "        \n",
    "        # close and open driver every 10 days to avoid captcha\n",
    "        if j % 10 == 0:\n",
    "            driver.quit()\n",
    "            driver = webdriver.Chrome(chromedriver_path)#, chrome_options=chromeOptions)\n",
    "            \n",
    "        url = f\"https://www.en.kayak.sa/flights/{sources[i]}-{destinations[i]}/{start_date+j}\"\n",
    "        driver.get(url)\n",
    "        sleep(15)\n",
    "        \n",
    "        # click show more button to get all flights\n",
    "        try:\n",
    "            show_more_button = driver.find_element_by_xpath('//a[@class = \"moreButton\"]')\n",
    "        except:\n",
    "            \n",
    "            # in case a captcha appears, require input from user so that the for loop pauses and the user can continue the\n",
    "            # loop after solving the captcha\n",
    "            input(\"Please solve the captcha then enter anything here to resume scraping.\")\n",
    "            \n",
    "        while True:\n",
    "            try:\n",
    "                show_more_button.click()\n",
    "                driver.implicitly_wait(10)\n",
    "            except:\n",
    "                break\n",
    "    \n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        airlines = get_airlines(soup)\n",
    "        total_stops = get_total_stops(soup)\n",
    "        prices = get_price(soup)\n",
    "        duration = get_duration(soup)\n",
    "        df = df.append(pd.DataFrame({\n",
    "            'Airline': airlines,\n",
    "            'Duration': duration,\n",
    "            'Total stops' : total_stops,\n",
    "            'Price' : prices,\n",
    "            'Date' : start_date+j\n",
    "                                    }))\n",
    "        \n",
    "    df['Source'] = sources[i]\n",
    "    df['Destination'] = destinations[i]\n",
    "    df = df.replace('\\n','', regex=True)\n",
    "    df = df.reset_index(drop = True)\n",
    "    \n",
    "    # save data as csv file for each route\n",
    "    df.to_csv(f'{sources[i]}_{destinations[i]}.csv',index=False)\n",
    "    print(f\"Succesfully saved {sources[i]} => {destinations[i]} route as {sources[i]}_{destinations[i]}.csv \")\n",
    "    \n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
